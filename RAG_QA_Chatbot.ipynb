{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "81662a30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81662a30",
        "outputId": "fd8bc35e-bdee-4e09-9aca-ce07b1ea374d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.11/dist-packages (1.26.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch transformers sentence-transformers PyMuPDF tqdm pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4fcb983a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fcb983a",
        "outputId": "6dd908c0-00cf-4d63-ffbe-b7d7193772c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries\n",
        "import torch\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import fitz  # PyMuPDF for PDF processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import textwrap\n",
        "import os\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ISYRi50zYm4z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISYRi50zYm4z",
        "outputId": "c6bdd8cd-0c7f-453b-c82f-a26b46b07c96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `RAG` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `RAG`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c31a63e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171,
          "referenced_widgets": [
            "011a499da9874e4092ee9da1248100b5",
            "291d7abcf65c4eb2a2c3aaf19d665e5c",
            "0d2f03c8ad7b440ca608ca00aeaa4d90",
            "d8c6710c9e054fd3ae3da211793807f7",
            "c33718951ae443e3a12d7db469e049c5",
            "3d42debfe88e4826bd5a0c67dfd97874",
            "00839dd4e4c848d895aeb6be0398e0a5",
            "257058218d1b46adbbb0f9c446c02063",
            "57847b1c1bd244d7a706087e3cbff0b4",
            "84649dd6b0ba48b3b4f5e4f6c6bd7c7a",
            "16d5debbca2948a8996deed8501d323b"
          ]
        },
        "id": "c31a63e2",
        "outputId": "0455d918-6ace-484c-ee2f-672719afe551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Loading embedding model...\n",
            "Embedding model loaded successfully!\n",
            "Loading Gemma LLM model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "011a499da9874e4092ee9da1248100b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemma LLM model loaded successfully!\n",
            "\n",
            " All models loaded and ready to use!\n"
          ]
        }
      ],
      "source": [
        "# Initialize GPU and models\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load embedding model\n",
        "print(\"Loading embedding model...\")\n",
        "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\", device=device)\n",
        "print(\"Embedding model loaded successfully!\")\n",
        "\n",
        "# Load Gemma LLM model\n",
        "print(\"Loading Gemma LLM model...\")\n",
        "model_id = \"google/gemma-2b-it\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "llm_model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16).to(device)\n",
        "print(\"Gemma LLM model loaded successfully!\")\n",
        "\n",
        "# Global variables for chatbot\n",
        "conversation_history = []\n",
        "pdf_chunks = []\n",
        "pdf_embeddings = None\n",
        "current_pdf_path = None\n",
        "\n",
        "print(\"\\n All models loaded and ready to use!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4096322f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4096322f",
        "outputId": "ea195a6a-3e7b-488c-d694-a68404272f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PDF processing functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "def process_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Extracts text from a PDF file and splits it into pages.\n",
        "    \"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    pages_and_texts = []\n",
        "    for page_number, page in tqdm(enumerate(doc), desc=\"Processing PDF pages\"):\n",
        "        text = page.get_text().replace(\"\\n\", \" \").strip()\n",
        "        if text:  # Only add non-empty pages\n",
        "            pages_and_texts.append({\"page_number\": page_number + 1, \"text\": text})\n",
        "    doc.close()\n",
        "    return pages_and_texts\n",
        "\n",
        "def chunk_text(text, max_tokens=128):\n",
        "    \"\"\"\n",
        "    Splits a large text into smaller chunks of a specified maximum token length.\n",
        "    \"\"\"\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "    current_length = 0\n",
        "\n",
        "    for word in words:\n",
        "        if current_length + len(word) + 1 > max_tokens:\n",
        "            if current_chunk:  # Only add non-empty chunks\n",
        "                chunks.append(\" \".join(current_chunk))\n",
        "            current_chunk = [word]\n",
        "            current_length = len(word)\n",
        "        else:\n",
        "            current_chunk.append(word)\n",
        "            current_length += len(word) + 1\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(\" \".join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def load_and_process_pdf(pdf_path):\n",
        "    \"\"\"\n",
        "    Loads and processes a PDF file, returning text chunks.\n",
        "    \"\"\"\n",
        "    global pdf_chunks, pdf_embeddings, current_pdf_path\n",
        "\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(f\" Error: PDF file not found at {pdf_path}\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        print(f\" Loading PDF: {os.path.basename(pdf_path)}\")\n",
        "\n",
        "        # Process PDF\n",
        "        pages_and_texts = process_pdf(pdf_path)\n",
        "\n",
        "        # Create chunks from all pages\n",
        "        all_chunks = []\n",
        "        for page in pages_and_texts:\n",
        "            page_chunks = chunk_text(page[\"text\"], max_tokens=128)\n",
        "            all_chunks.extend(page_chunks)\n",
        "\n",
        "        pdf_chunks = all_chunks\n",
        "        current_pdf_path = pdf_path\n",
        "\n",
        "        print(f\" PDF processed successfully! ({len(pdf_chunks)} chunks created)\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing PDF: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "print(\" PDF processing functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "795cea1e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "795cea1e",
        "outputId": "e49946c4-a35e-46ff-ff7b-3330f4e10750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Embedding functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "def embed_chunks(chunks):\n",
        "    \"\"\"\n",
        "    Embeds text chunks using the embedding model.\n",
        "    \"\"\"\n",
        "    if not chunks:\n",
        "        return None\n",
        "\n",
        "    print(f\" Creating embeddings for {len(chunks)} chunks...\")\n",
        "    embeddings = embedding_model.encode(chunks, batch_size=32, convert_to_tensor=True, show_progress_bar=True)\n",
        "    print(\" Embeddings created successfully!\")\n",
        "    return embeddings\n",
        "\n",
        "def create_pdf_embeddings():\n",
        "    \"\"\"\n",
        "    Creates embeddings for the currently loaded PDF chunks.\n",
        "    \"\"\"\n",
        "    global pdf_embeddings\n",
        "\n",
        "    if not pdf_chunks:\n",
        "        print(\" No PDF chunks found. Please load a PDF first.\")\n",
        "        return False\n",
        "\n",
        "    pdf_embeddings = embed_chunks(pdf_chunks)\n",
        "    if pdf_embeddings is not None:\n",
        "        print(f\" Created embeddings for {len(pdf_chunks)} chunks\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\" Failed to create embeddings\")\n",
        "        return False\n",
        "\n",
        "print(\" Embedding functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "67563af2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67563af2",
        "outputId": "90198bee-a518-4236-9b64-b6a86713e27f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Context retrieval functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "def retrieve_relevant_chunks(query, embeddings, chunks, top_k=5):\n",
        "    \"\"\"\n",
        "    Retrieves the most relevant chunks for a query using cosine similarity.\n",
        "    \"\"\"\n",
        "    if not query or embeddings is None or not chunks:\n",
        "        return []\n",
        "\n",
        "    # Generate query embedding\n",
        "    query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    scores = util.cos_sim(query_embedding, embeddings)[0]\n",
        "\n",
        "    # Get top k results\n",
        "    top_results = torch.topk(scores, k=min(top_k, len(chunks)))\n",
        "\n",
        "    # Return chunks with their similarity scores\n",
        "    relevant_chunks = []\n",
        "    for idx in top_results.indices:\n",
        "        chunk_text = chunks[idx]\n",
        "        similarity_score = scores[idx].item()\n",
        "        relevant_chunks.append((chunk_text, similarity_score))\n",
        "\n",
        "    return relevant_chunks\n",
        "\n",
        "def display_retrieved_chunks(relevant_chunks):\n",
        "    \"\"\"\n",
        "    Display the retrieved chunks with their similarity scores.\n",
        "    \"\"\"\n",
        "    if not relevant_chunks:\n",
        "        print(\" No relevant chunks found.\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\n Retrieved {len(relevant_chunks)} relevant chunks:\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    for i, (chunk, score) in enumerate(relevant_chunks, 1):\n",
        "        print(f\"\\n Chunk {i} (Similarity: {score:.3f}):\")\n",
        "        print(f\" {chunk[:200]}{'...' if len(chunk) > 200 else ''}\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "print(\" Context retrieval functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "a12a841f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a12a841f",
        "outputId": "836b9453-4e12-418b-d5c9-5ed28dc0d437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " LLM response generation functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "def format_chatbot_prompt(query, context_items, conversation_history):\n",
        "    \"\"\"\n",
        "    Formats the query, context, and conversation history into a structured prompt for the LLM.\n",
        "    \"\"\"\n",
        "    # Format context\n",
        "    context = \"\\n\".join([f\"- {item}\" for item in context_items])\n",
        "\n",
        "    # Include recent conversation history (last 3 exchanges)\n",
        "    history_context = \"\"\n",
        "    if conversation_history:\n",
        "        recent_history = conversation_history[-6:]  # Last 3 Q&A pairs\n",
        "        history_context = \"\\n\".join([f\"Previous: {entry}\" for entry in recent_history])\n",
        "\n",
        "    # Create the prompt\n",
        "    prompt = f\"\"\"You are a helpful AI assistant that answers questions based on the provided context from a PDF document.\n",
        "Use the context to provide accurate and helpful answers. If the context doesn't contain enough information to answer the question, say so politely.\n",
        "\n",
        "Context from PDF:\n",
        "{context}\n",
        "\n",
        "{history_context}\n",
        "\n",
        "Current Question: {query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    return prompt.strip()\n",
        "\n",
        "def generate_response(query):\n",
        "    \"\"\"\n",
        "    Generates a response for a given query using the RAG pipeline.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Check if we have embeddings\n",
        "        if pdf_embeddings is None or not pdf_chunks:\n",
        "            return {\n",
        "                'answer': \"Please load a PDF first before asking questions.\",\n",
        "                'verification': \"No PDF loaded \",\n",
        "                'context_items': []\n",
        "            }\n",
        "\n",
        "        # Retrieve relevant chunks\n",
        "        relevant_chunks = retrieve_relevant_chunks(query, pdf_embeddings, pdf_chunks, top_k=5)\n",
        "        context_items = [item[0] for item in relevant_chunks]\n",
        "\n",
        "        if not context_items:\n",
        "            return {\n",
        "                'answer': \"I couldn't find relevant information in the PDF to answer your question.\",\n",
        "                'verification': \"No relevant context found \",\n",
        "                'context_items': []\n",
        "            }\n",
        "\n",
        "        # Format the prompt with conversation history\n",
        "        prompt = format_chatbot_prompt(query, context_items, conversation_history)\n",
        "\n",
        "        # Generate response\n",
        "        input_ids = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = llm_model.generate(\n",
        "                input_ids[\"input_ids\"],\n",
        "                max_new_tokens=256,\n",
        "                temperature=0.7,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.eos_token_id,\n",
        "                eos_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode the response\n",
        "        full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract only the new response (after the prompt)\n",
        "        if \"Answer:\" in full_response:\n",
        "            answer = full_response.split(\"Answer:\")[-1].strip()\n",
        "        else:\n",
        "            answer = full_response[len(prompt):].strip()\n",
        "\n",
        "        # Clean up the answer\n",
        "        answer = answer.replace(\"Assistant:\", \"\").strip()\n",
        "\n",
        "        return {\n",
        "            'answer': answer,\n",
        "            'context_items': context_items,\n",
        "            'relevant_chunks': relevant_chunks\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error generating response: {str(e)}\")\n",
        "        return {\n",
        "            'answer': \"I encountered an error while generating the response. Please try again.\",\n",
        "            'verification': f\"Error: {str(e)} \",\n",
        "            'context_items': []\n",
        "        }\n",
        "\n",
        "print(\" LLM response generation functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "cbf9eb7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbf9eb7e",
        "outputId": "9f9de855-34f5-425a-8ddf-24bdfe34f26b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Fact verification functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "def verify_facts(answer, context_items, threshold=0.7):\n",
        "    \"\"\"\n",
        "    Verifies if the generated answer aligns with the retrieved context.\n",
        "    \"\"\"\n",
        "    if not answer or not context_items:\n",
        "        return \"No content to verify \"\n",
        "\n",
        "    try:\n",
        "        # Combine all context items\n",
        "        combined_context = \" \".join(context_items)\n",
        "\n",
        "        # Generate embeddings for answer and context\n",
        "        answer_embedding = embedding_model.encode(answer, convert_to_tensor=True)\n",
        "        context_embedding = embedding_model.encode(combined_context, convert_to_tensor=True)\n",
        "\n",
        "        # Calculate similarity\n",
        "        similarity_score = util.cos_sim(answer_embedding, context_embedding).item()\n",
        "\n",
        "        # Verify based on threshold\n",
        "        if similarity_score >= threshold:\n",
        "            return f\"Fact Verified (Similarity: {similarity_score:.3f})\"\n",
        "        else:\n",
        "            return f\"Fact Verification Uncertain (Similarity: {similarity_score:.3f})\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Verification Error ({str(e)})\"\n",
        "\n",
        "def display_verification_details(answer, context_items):\n",
        "    \"\"\"\n",
        "    Display detailed verification information.\n",
        "    \"\"\"\n",
        "    verification_result = verify_facts(answer, context_items)\n",
        "\n",
        "    print(f\"\\n Fact Verification:\")\n",
        "    print(f\" {verification_result}\")\n",
        "\n",
        "    if context_items:\n",
        "        print(f\" Based on {len(context_items)} context chunks\")\n",
        "        print(f\" Context relevance helps ensure answer accuracy\")\n",
        "\n",
        "print(\" Fact verification functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "50acce5b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50acce5b",
        "outputId": "7109a95c-adf0-4f2f-f9fe-afe936a034b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Helper functions defined successfully!\n"
          ]
        }
      ],
      "source": [
        "def clear_conversation():\n",
        "    \"\"\"\n",
        "    Clears the conversation history.\n",
        "    \"\"\"\n",
        "    global conversation_history\n",
        "    conversation_history = []\n",
        "    print(\" Conversation history cleared!\")\n",
        "    if current_pdf_path:\n",
        "        print(f\" Current PDF: {os.path.basename(current_pdf_path)}\")\n",
        "\n",
        "def display_pdf_info():\n",
        "    \"\"\"\n",
        "    Displays information about the currently loaded PDF.\n",
        "    \"\"\"\n",
        "    if current_pdf_path and pdf_chunks:\n",
        "        print(f\"\\ Current PDF: {os.path.basename(current_pdf_path)}\")\n",
        "        print(f\" Total chunks: {len(pdf_chunks)}\")\n",
        "        print(f\" Average chunk length: {sum(len(chunk.split()) for chunk in pdf_chunks) / len(pdf_chunks):.1f} words\")\n",
        "        print(f\" Embeddings: {' Ready' if pdf_embeddings is not None else ' Not created'}\")\n",
        "    else:\n",
        "        print(\" No PDF currently loaded.\")\n",
        "\n",
        "def display_help():\n",
        "    \"\"\"\n",
        "    Display help information.\n",
        "    \"\"\"\n",
        "    print(\"\\n Available commands:\")\n",
        "    print(\"  • Ask any question about the loaded PDF\")\n",
        "    print(\"  • 'clear' - Clear conversation history\")\n",
        "    print(\"  • 'info' - Show PDF information\")\n",
        "    print(\"  • 'help' - Show this help message\")\n",
        "    print(\"  • 'quit' or 'exit' - Exit the chatbot\")\n",
        "    print(\"  • 'show context' - Display retrieved context for last question\")\n",
        "\n",
        "def load_pdf_interactive():\n",
        "    \"\"\"\n",
        "    Interactive PDF loading with user input.\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        pdf_path = input(\"\\n Enter the path to your PDF file: \").strip()\n",
        "\n",
        "        if pdf_path.lower() in ['quit', 'exit', 'q']:\n",
        "            print(\" Goodbye!\")\n",
        "            return False\n",
        "\n",
        "        if not pdf_path:\n",
        "            print(\" Please enter a valid PDF path.\")\n",
        "            continue\n",
        "\n",
        "        if load_and_process_pdf(pdf_path):\n",
        "            if create_pdf_embeddings():\n",
        "                display_pdf_info()\n",
        "                return True\n",
        "            else:\n",
        "                print(\" Failed to create embeddings. Please try another PDF.\")\n",
        "        else:\n",
        "            print(\" Please try another PDF or 'quit' to exit.\")\n",
        "\n",
        "print(\" Helper functions defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "298dfc27",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "298dfc27",
        "outputId": "bd85277c-6ff9-4e96-c482-cb7704050ae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Main chatbot loop function defined successfully!\n"
          ]
        }
      ],
      "source": [
        "def chat_with_pdf():\n",
        "    \"\"\"\n",
        "    Main interactive chat loop.\n",
        "    \"\"\"\n",
        "    global conversation_history\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\" RAG PDF Q&A Chatbot - Interactive Version\")\n",
        "    print(\"=\"*60)\n",
        "    print(\" Powered by Gemma LLM and SentenceTransformers\")\n",
        "    print(\" Type 'help' for available commands\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Store last response for context display\n",
        "    last_response = None\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Get user input\n",
        "            user_input = input(\"\\n You: \").strip()\n",
        "\n",
        "            # Handle special commands\n",
        "            if user_input.lower() in ['quit', 'exit', 'q']:\n",
        "                print(\" Thank you for using the RAG PDF Chatbot! Goodbye!\")\n",
        "                break\n",
        "\n",
        "            elif user_input.lower() == 'clear':\n",
        "                clear_conversation()\n",
        "                continue\n",
        "\n",
        "            elif user_input.lower() == 'help':\n",
        "                display_help()\n",
        "                continue\n",
        "\n",
        "            elif user_input.lower() == 'info':\n",
        "                display_pdf_info()\n",
        "                continue\n",
        "\n",
        "            elif user_input.lower() == 'show context':\n",
        "                if last_response and 'relevant_chunks' in last_response:\n",
        "                    display_retrieved_chunks(last_response['relevant_chunks'])\n",
        "                else:\n",
        "                    print(\" No recent context available. Ask a question first.\")\n",
        "                continue\n",
        "\n",
        "            elif not user_input:\n",
        "                print(\" Please enter a question or command.\")\n",
        "                continue\n",
        "\n",
        "            # Check if PDF is loaded\n",
        "            if not pdf_chunks or pdf_embeddings is None:\n",
        "                print(\" Please load a PDF first!\")\n",
        "                continue\n",
        "\n",
        "            # Generate response\n",
        "            print(\" AI is thinking...\")\n",
        "            response = generate_response(user_input)\n",
        "\n",
        "            if response and response['answer']:\n",
        "                timestamp = datetime.now().strftime(\"%H:%M:%S\")\n",
        "\n",
        "                # Display the response with text wrapping\n",
        "                wrapped_answer = textwrap.fill(response['answer'], width=80) # Adjust width as needed\n",
        "                print(f\"\\n[{timestamp}]  AI: {wrapped_answer}\")\n",
        "\n",
        "                # Display verification if we have context\n",
        "                if response['context_items']:\n",
        "                    verification_result = verify_facts(response['answer'], response['context_items'])\n",
        "                    print(f\" {verification_result}\")\n",
        "\n",
        "                # Update conversation history\n",
        "                conversation_history.append(f\"Q: {user_input}\")\n",
        "                conversation_history.append(f\"A: {response['answer']}\")\n",
        "\n",
        "                # Keep only last 10 exchanges to manage memory\n",
        "                if len(conversation_history) > 20:\n",
        "                    conversation_history = conversation_history[-20:]\n",
        "\n",
        "                # Store for context display\n",
        "                last_response = response\n",
        "\n",
        "            else:\n",
        "                print(\" Sorry, I couldn't generate a response. Please try again.\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n Chat interrupted. Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\" Error: {str(e)}\")\n",
        "            print(\" Please try again or type 'help' for commands.\")\n",
        "\n",
        "print(\" Main chatbot loop function defined successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cafeb56a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3db7dcfa616d403f88ae96b5ec7a2789",
            "95882da62224492b9a03b379a5a1be1c",
            "e7e9f18d88094c59962a54dd230a53f4",
            "769444264f314292977fdc0676c83d3a",
            "fcc971e075d3400f8eb85f27310bd6c7",
            "a48f8210b41849f5ba0abed5e5cb2bea",
            "4aecc8fb772345f5938aad99fd4f5028",
            "3c22d515660946d69d4bbcc3f25ef418",
            "16d59fa958bb4ff5a39bc660ffacd845",
            "455f1c69c98349b9ba76d42ebc5e8bea",
            "190f25f5ff3941cdbca428c37f919dc1",
            "bf8a2c20a7244f71adc976f3edb8a9bc",
            "2ad06cf4f2de4e28a517816c485a82ea",
            "7a7201901d5d42638efad5f33b9a07b2",
            "e2bcc1e5bb9943ddac0c355daf646f15",
            "5fff5fb6c54842e291dbcec575f771a1",
            "01761ceb5dde42e1b32cae952dd4dbd3",
            "28d40a96aaa648c79020d0892dd709ff",
            "c3c0588814c44d2abbc4e8f6b3bd5f25",
            "d272b760ffaf41a6b4f931f7eb3a70e9",
            "73d92bf00e5d4fdfa96c2ab17cfe0caf",
            "10f3564c54e34a1b8f6f0ba829600d43"
          ]
        },
        "id": "cafeb56a",
        "outputId": "73c383c9-dc8d-4401-c311-ff7fe0be8dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Welcome to the RAG PDF Q&A Chatbot!\n",
            " Running on: cpu\n",
            " All models loaded and ready!\n",
            "\n",
            " Enter the path to your PDF file: /content/Abraham Silberschatz-Operating System Concepts (9th,2012_12).pdf\n",
            " Loading PDF: Abraham Silberschatz-Operating System Concepts (9th,2012_12).pdf\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Processing PDF pages: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3db7dcfa616d403f88ae96b5ec7a2789"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " PDF processed successfully! (18831 chunks created)\n",
            " Creating embeddings for 18831 chunks...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/589 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf8a2c20a7244f71adc976f3edb8a9bc"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Embeddings created successfully!\n",
            " Created embeddings for 18831 chunks\n",
            "\\ Current PDF: Abraham Silberschatz-Operating System Concepts (9th,2012_12).pdf\n",
            " Total chunks: 18831\n",
            " Average chunk length: 20.0 words\n",
            " Embeddings:  Ready\n",
            "\n",
            "============================================================\n",
            " RAG PDF Q&A Chatbot - Interactive Version\n",
            "============================================================\n",
            " Powered by Gemma LLM and SentenceTransformers\n",
            " Type 'help' for available commands\n",
            "============================================================\n",
            "\n",
            " You: what is an operating system?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " AI is thinking...\n",
            "\n",
            "[10:18:20]  AI: An operating system is a program that manages a computer’s hardware. It also provides a basis for programs that are executed on behalf of the user.\n",
            " Fact Verified (Similarity: 0.930)\n",
            "\n",
            " You: what is cpu scheduling\n",
            " AI is thinking...\n",
            "\n",
            "[10:20:50]  AI: CPU scheduling is the task of selecting a waiting process from the ready queue and allocating the CPU to it.\n",
            " Fact Verified (Similarity: 0.825)\n",
            "\n",
            " You: what is disk scheduling\n",
            " AI is thinking...\n",
            "\n",
            "[10:23:21]  AI: Disk scheduling is the task of selecting a waiting disk from the ready queue and allocating the disk to it.\n",
            " Fact Verified (Similarity: 0.759)\n",
            "\n",
            " You: what are the diffrent types of memory\n",
            " AI is thinking...\n",
            "\n",
            "[10:25:42]  AI: The context does not provide information about the different types of memory, so I cannot answer this question from the context.\n",
            " Fact Verification Uncertain (Similarity: 0.690)\n",
            "\n",
            " You: what is the memory hierarchy\n",
            " AI is thinking...\n",
            "\n",
            "[10:28:39]  AI: The context does not provide information about the memory hierarchy, so I cannot answer this question from the context.\n",
            " Fact Verified (Similarity: 0.707)\n",
            "\n",
            " You: q\n",
            " Thank you for using the RAG PDF Chatbot! Goodbye!\n"
          ]
        }
      ],
      "source": [
        "# Main execution - Load PDF and start chatbot\n",
        "print(\" Welcome to the RAG PDF Q&A Chatbot!\")\n",
        "print(f\" Running on: {device}\")\n",
        "print(\" All models loaded and ready!\")\n",
        "\n",
        "# Load PDF first\n",
        "if load_pdf_interactive():\n",
        "    # Start the interactive chat\n",
        "    chat_with_pdf()\n",
        "else:\n",
        "    print(\" No PDF loaded. Please restart and try again.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "011a499da9874e4092ee9da1248100b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_291d7abcf65c4eb2a2c3aaf19d665e5c",
              "IPY_MODEL_0d2f03c8ad7b440ca608ca00aeaa4d90",
              "IPY_MODEL_d8c6710c9e054fd3ae3da211793807f7"
            ],
            "layout": "IPY_MODEL_c33718951ae443e3a12d7db469e049c5"
          }
        },
        "291d7abcf65c4eb2a2c3aaf19d665e5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d42debfe88e4826bd5a0c67dfd97874",
            "placeholder": "​",
            "style": "IPY_MODEL_00839dd4e4c848d895aeb6be0398e0a5",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "0d2f03c8ad7b440ca608ca00aeaa4d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_257058218d1b46adbbb0f9c446c02063",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57847b1c1bd244d7a706087e3cbff0b4",
            "value": 2
          }
        },
        "d8c6710c9e054fd3ae3da211793807f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84649dd6b0ba48b3b4f5e4f6c6bd7c7a",
            "placeholder": "​",
            "style": "IPY_MODEL_16d5debbca2948a8996deed8501d323b",
            "value": " 2/2 [00:29&lt;00:00, 12.20s/it]"
          }
        },
        "c33718951ae443e3a12d7db469e049c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d42debfe88e4826bd5a0c67dfd97874": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00839dd4e4c848d895aeb6be0398e0a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "257058218d1b46adbbb0f9c446c02063": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57847b1c1bd244d7a706087e3cbff0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84649dd6b0ba48b3b4f5e4f6c6bd7c7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16d5debbca2948a8996deed8501d323b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3db7dcfa616d403f88ae96b5ec7a2789": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95882da62224492b9a03b379a5a1be1c",
              "IPY_MODEL_e7e9f18d88094c59962a54dd230a53f4",
              "IPY_MODEL_769444264f314292977fdc0676c83d3a"
            ],
            "layout": "IPY_MODEL_fcc971e075d3400f8eb85f27310bd6c7"
          }
        },
        "95882da62224492b9a03b379a5a1be1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a48f8210b41849f5ba0abed5e5cb2bea",
            "placeholder": "​",
            "style": "IPY_MODEL_4aecc8fb772345f5938aad99fd4f5028",
            "value": "Processing PDF pages: "
          }
        },
        "e7e9f18d88094c59962a54dd230a53f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c22d515660946d69d4bbcc3f25ef418",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16d59fa958bb4ff5a39bc660ffacd845",
            "value": 1
          }
        },
        "769444264f314292977fdc0676c83d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_455f1c69c98349b9ba76d42ebc5e8bea",
            "placeholder": "​",
            "style": "IPY_MODEL_190f25f5ff3941cdbca428c37f919dc1",
            "value": " 944/? [00:11&lt;00:00, 193.28it/s]"
          }
        },
        "fcc971e075d3400f8eb85f27310bd6c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a48f8210b41849f5ba0abed5e5cb2bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aecc8fb772345f5938aad99fd4f5028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c22d515660946d69d4bbcc3f25ef418": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "16d59fa958bb4ff5a39bc660ffacd845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "455f1c69c98349b9ba76d42ebc5e8bea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "190f25f5ff3941cdbca428c37f919dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf8a2c20a7244f71adc976f3edb8a9bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ad06cf4f2de4e28a517816c485a82ea",
              "IPY_MODEL_7a7201901d5d42638efad5f33b9a07b2",
              "IPY_MODEL_e2bcc1e5bb9943ddac0c355daf646f15"
            ],
            "layout": "IPY_MODEL_5fff5fb6c54842e291dbcec575f771a1"
          }
        },
        "2ad06cf4f2de4e28a517816c485a82ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01761ceb5dde42e1b32cae952dd4dbd3",
            "placeholder": "​",
            "style": "IPY_MODEL_28d40a96aaa648c79020d0892dd709ff",
            "value": "Batches: 100%"
          }
        },
        "7a7201901d5d42638efad5f33b9a07b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3c0588814c44d2abbc4e8f6b3bd5f25",
            "max": 589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d272b760ffaf41a6b4f931f7eb3a70e9",
            "value": 589
          }
        },
        "e2bcc1e5bb9943ddac0c355daf646f15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d92bf00e5d4fdfa96c2ab17cfe0caf",
            "placeholder": "​",
            "style": "IPY_MODEL_10f3564c54e34a1b8f6f0ba829600d43",
            "value": " 589/589 [39:43&lt;00:00,  1.27it/s]"
          }
        },
        "5fff5fb6c54842e291dbcec575f771a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01761ceb5dde42e1b32cae952dd4dbd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28d40a96aaa648c79020d0892dd709ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3c0588814c44d2abbc4e8f6b3bd5f25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d272b760ffaf41a6b4f931f7eb3a70e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73d92bf00e5d4fdfa96c2ab17cfe0caf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10f3564c54e34a1b8f6f0ba829600d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}